\documentclass{article}

\title{Review on "The Symbol Grounding Problem has been solved. So whats next?" by Luc Steels}
\date{18/Jan/2018}
\author{Irdi Balla}

\begin{document}
	\maketitle	
	\section{Symbols}
	The semiotic tradition makes a distinction between symbols, objects and concept. The symbol is the writing or drawing which manifests in the real world in the form of an object, while the concept is associated with the symbol through the method. This is also called the semiotic triad. The method usually constraints the use of the symbol the object. It could be a classifier or pattern recognition process. If this method is available then the symbol is considered grounded. Not every symbol can be grounded. Abstractions for example are not grounded. 
	\subsection{Semiotic Networks}
	Aside from the semiotic relations in the triad there are also some other relations that come into play. Steels lists the following.
	\begin{enumerate}
		\item Objects occur in a context
		\item Symbols co-occur with other symbols in texts and speech
		\item Concepts may have semnatic relations among them
		\item There are relations between methods
	\end{enumerate}
	Human beings use these links efficiently and are able to incorporate their usage in their everyday lives. \\
	Steels calls the set of links in the triad a semiotic network. Individuals have their own semiotic network and they navigate through it and expand /reshuffle it based on the needs of the communication processes.
	\subsection{Collective Semiotic Dynamics}
	Symbols play a huge role in the development of individuals, especially in social interaction. The individual semiotic networks are coordinated in groups based on feedback they receive from one-another. Studies of natural dialog point to the fact that individuals adopt their system during the course of a conversation. Studies of emergent communication show that detecting miscommunication and introducing new symbols is the main skill required to establish such a shared connection.
	Steels introduces the notion of "Semiotic Landscape" as the "set of all semiotic networks of a population of interacting individuals". The landscape changes frequently but there are also some general tendencies. But even though these general tendencies exit semiotic networks will not be exactly the same between different individuals as the network is tied to personal experience.
	\subsection{The Symbol Grounding Problem}
	AI has existed for several decades now and one could argue that Shakey the robot was able to understand commands and react to them since the seventies. THe problem with Shakey was that it was all programmed. The semiotic network was not formed autonomously but rather it was carefully mapped by human programmers. In Shakey's case the computational system could not generate semantics while our system can. Even then it was understood that it was not feasible to program all methods by hand but rather the AI had to autonomously establish a semiotic network of its own. The next step was to introduce supervised learning but even that, according to Steels, fails to solve the Symbol Grounding Problem. It fails in the sense that there is still a lot of human interaction in the process of creating the semiotic network.
	\section{Meaning}
	The relation between representation and meaning offers ground for another debate on the importance of representation in cognition.
	\subsection{Representation and Meaning}
	A representation is defined as a stand-in for something else, so that it can be made present again. A representation is accepted by the hearer as noted by the speaker. There is no rule as to what can be a representation and what cannot, but it helps when the representation and the represented have properties in common.\\
	Furthermore Steels makes a distinction between and icon,an index and a symbol. The icon looks like the thing it signifies(e.g. a statue). An index does not look like the thing it signifies but there still is some connection between the two objects(e.g smoke is an index of a fire). A symbol on the other has no relation to the thing it signifies, and its meaning is set by conventions. \\
	Human representations rarely depict physical things, but rather they prefer meanings. A meaning is a feature that is relevant to the current interaction.
	A representation represents a meaning but they are not the same thing. \\
	Understanding a representation is not an easy process. It requires the selection of relevant meanings and invoking them. Also it might require perspective or point-of-view. Our representations help us engage with the world due to the fact that they are very rich.
	\subsection{Representation in Computer Science}
	Computer scientists have adopted the term representation but they mainly focus on the creation of a 'stand-in' aspect of it. There is belief among computational neuroscientists that these representations in computer science context also exist in the brain. \\
	Steels describes the difference	between symbolic and non-symbolic computer science representations. Symbolic ones are representations of categories or classes that are relevant for reasoning and planning while non-symbolic representations make use of continuous values. Steels argues that both these representations are needed in order to achieve a fully functional AI. using only one of them could have certain improvements in certain scenarios but it incorporating them brings out better overall results.
	\section{Embodiment}
	Same as with the notion of symbol and representation, computer scientists, capture only limited aspect of embodiment as well.
	\subsection{Embodiment as implementation}
	The term embodiment refers to the implementation or the physical realization of a method or idea. Computer scientists take a systems perspective while physical natural scientists seek material explanation to understand phenomena.THe goal for computer scientists is to identify the algorithms responsible for cognition. Even if the algorithm is understood there is still a lot of work to convert it in an embodiment. On the other hand some biologists and philosophers find it hard to believe the fact that cognition could be implemented on other mediums except for the biological environment of the brain. \\
	As times have progressed many activities that were believed to be material-specific, are now reachable in different environments andthrough different mediums (e.g. photosynthesis is possible in different materials).
	These advances have raised the popularity of a systematic viewpoint even among biologists.
	\subsection{Embodiment as having a physical body}
	Another notion of embodiment refers to the fact of having a body. When seen this way it is clear that this is a prerequisite to symbol grounding. It is likely that the human body helps in making interactions with the environment easy through it bio-physical properties and this could limit the similarity that an AI can have in relation to human intelligence.
	\section{A Solution to the Symbol Grounding Problem?}
	Steels proposes a step-by-step guide as to how we can achieve a solution to the symbol grounding problem.
	\begin{enumerate}
		\item Having a physically embodied autonomous agent
		\item A mechanism by which an agent can generate his own meanings
		\item A mechanism by which an agent can represent and ground relevant meanings
		\item A mechanism for autonomously establishing and negotiating symbols to express meaning
		\item An environment for agents to modify their meanings by interacting with other agents
	\end{enumerate}
	Steels demonstrates this steps in his own research of creating a mutual language for understanding color, in a color game, by agents(robots) who have no prior knowledge on the field. According to his tests the agents after some time agree on the usage of symbols do describe different concepts and they seem to be able to share this information among each other to invoke meanings. He also states that this success was not from the identification of some biochemical substance but rather a system explanation of semiotic networks and dynamics.
	
	
\end{document}
